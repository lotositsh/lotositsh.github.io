
<!DOCTYPE html>

<html><head>
<meta charset="utf-8"/>
<link href="../css/text.css" rel="stylesheet"/>
<title>Нейронная сеть для выполнения перефразировки фразы</title>
<link href="../img/favicon.png" rel="icon" sizes="192x192" type="image/png"/>
<meta content="width=device-width" name="viewport"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="Нейронная сеть для выполнения перефразировки фразы" name="description"/>
<meta content="Нейросеть, перефразировать фразу" name="keywords"/>
<meta content="summary" name="twitter:card"/>
<meta content="Нейронная сеть для выполнения перефразировки фразы" name="twitter:title"/>
<meta content="Используем нейросеть чтобы перефразировать" name="twitter:description"/>
<meta content="img/" name="twitter:image"/>
<meta content="article" property="og:type"/>
<meta content="Нейронная сеть для выполнения перефразировки фразы" property="og:title"/>
<meta content="Используем нейросеть чтобы перефразировать" property="og:description"/>
<meta content="img/neiro.webp" property="og:image"/>
<meta content="DzenIT" property="og:site_name"/>
</head>
<body> <div class="size1">
<div class="header">
<h2>DzenIT</h2>
</div>
<div class="topnav">
<a href="../index.html">HOME</a>
<a href="../zen.html">ZEN</a>
<a href="../it.html">IT</a>
<a href="../soft.html">SOFT</a>
<a href="../apk.html">APK</a>
<a href="../live.html">LIVE</a>
<a href="../game.html">GAME</a>
<a href="../other.html">OTHER</a>
<a href="../w.html">W</a>
<a href="../about.html">CONTACT</a>
<a href="#" id="searchLink">SEARCH</a>
<script>
  document.getElementById('searchLink').addEventListener('click', function(event) {
    event.preventDefault(); // Prevent the default behavior of the link
    var searchBox = document.getElementById('searchBox');
    if (searchBox.style.display === 'none' || searchBox.style.display === '') {
      searchBox.style.display = 'block';
    } else {
      searchBox.style.display = 'none';
    }
  });
</script>
<div id="searchBox" style="display: none;">
<table border="0" cellpadding="0" cellspacing="0">
<tr>
<td colspan="2" style="font-family: Arial, Helvetica, sans-serif; font-size: 7.5pt;">
<form accept-charset="utf-8" action="https://search.freefind.com/find.html" method="get" style="margin:0px; margin-top:4px;" target="_blank">
<input name="si" type="hidden" value="41025751"/>
<input name="pid" type="hidden" value="r"/>
<input name="n" type="hidden" value="0"/>
<input name="_charset_" type="hidden" value=""/>
<input name="bcd" type="hidden" value="÷"/>
<input name="query" size="15" type="text"/>
<input type="submit" value="search"/>
</form>
</td>
</tr>
<tr>
</tr>
</table>
</div>
</div>
<center><h1>Нейронная сеть для выполнения перефразировки фразы</h1></center>
<p>Если вам нужно качественно перефразировать фразу, можно использовать метод back-translation, переводим на английский, потом обратно на русский. Чтобы избежать повторения одной и той же фразы, модельный переводчик может запретить воспроизводить n-грамм (токен), найденные в оригинальном предложении.</p>
<p>Введенная фраза</p>
<p><em>Так же, как эта чашка, — сказал Нан-ин, — Вы полны Ваших собственных мнений и размышлений</em></p>
<p>Результат</p>
<p><em>Как и в этой чаше, сказал Нань Ин, вы полны собственных мыслей и желаний."</em></p>
<p>Сам код в colab</p>
<pre>!nvidia-smi4
!pip install transformers
!pip install sacremoses
import torch
from transformers import FSMTModel, FSMTTokenizer, FSMTForConditionalGeneration
tokenizer = FSMTTokenizer.from_pretrained("facebook/wmt19-en-ru")
model = FSMTForConditionalGeneration.from_pretrained("facebook/wmt19-en-ru")
inverse_tokenizer = FSMTTokenizer.from_pretrained("facebook/wmt19-ru-en")
inverse_model = FSMTForConditionalGeneration.from_pretrained("facebook/wmt19-ru-en")
model.cuda();
inverse_model.cuda();

def paraphrase(text, gram=4, num_beams=5, **kwargs):
    """ Generate a paraphrase using back translation. 
    Parameter `gram` denotes size of token n-grams of the original sentence that cannot appear in the paraphrase.
    """
    input_ids = inverse_tokenizer.encode(text, return_tensors="pt")
    with torch.no_grad():
        outputs = inverse_model.generate(input_ids.to(inverse_model.device), num_beams=num_beams, **kwargs)
    other_lang = inverse_tokenizer.decode(outputs[0], skip_special_tokens=True)
    # print(other_lang)
    input_ids = input_ids[0, :-1].tolist()
    bad_word_ids = [input_ids[i:(i+gram)] for i in range(len(input_ids)-gram)]
    input_ids = tokenizer.encode(other_lang, return_tensors="pt")
    with torch.no_grad():
        outputs = model.generate(input_ids.to(model.device), num_beams=num_beams, bad_words_ids=bad_word_ids, **kwargs)
    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return decoded
	
text = input('Enter text:\n ')
print(paraphrase(text, gram=3, do_sample=False))</pre>
<p>Закомментировав строки ниже, можно обойтись традиционным процессором вместо графической карты</p>
<pre> #model.cuda();</pre>
<pre>#inverse_model.cuda();</pre>
<p>Изучить этот код можно самостоятельно в <a href="https://colab.research.google.com/drive/1xEF_7zKV6ZSj3Hl4NVeQFdpZQzVE4VZN?usp=sharing" target="_blank">colab</a></p>
<p>Используя данный код можно даже целые тексты перефразировать построчно. Нужно лишь добавить текстовый файл себе в проект и прописать в конце код:</p>
<pre>
import time
f = open("text.txt", "r", encoding='utf-8')
f2 = open("new_text_721.txt", "a", encoding='utf-8')
count = 0
for line in f:
    try:
        print(line)
        print (paraphrase(line, gram=3, do_sample=False))
        f2.write(paraphrase(line, gram=3, do_sample=False) + '\n')
        time.sleep(0.5)
        count += 1
        print(count)
    except:
        print(line)
        print (paraphrase(line, gram=3, do_sample=False))
        f2.write(paraphrase(line, gram=3, do_sample=False) + '\n')
        time.sleep(0.5)
        count += 1
        print(count)


f2.close()  
print(count)
</pre>
 try и except добавлены, т.к. были замечены непредвиденные ошибки в выполнении, а счетчик count поможет определить на какой строке мы остановились 
<br><br><br><footer>lotositsh.github.io. All rights reserved. © 2025</footer></div> </body>
</html>
